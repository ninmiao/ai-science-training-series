{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662a93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19878bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "573fda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da412dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40200, 28, 28)\n",
      "(40200, 784)\n",
      "\n",
      "MNIST data loaded: train: 40200 val: 19800 test: 10000\n",
      "X_train: (40200, 784)\n",
      "y_train: (40200,)\n"
     ]
    }
   ],
   "source": [
    "# repeating the data prep from the previous notebook\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# EDIT: splitting training data into train and val because this is better practice than using test data to\n",
    "# choose models/hyperparameters\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "x_train = x_train.astype(numpy.float32)\n",
    "# EDIT: adding pre-processing to validation data \n",
    "x_val  = x_val.astype(numpy.float32)\n",
    "x_test  = x_test.astype(numpy.float32)\n",
    "\n",
    "x_train /= 255.\n",
    "x_val  /= 255.\n",
    "x_test  /= 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], numpy.prod(x_train[0,:,:].shape))\n",
    "x_val = x_val.reshape(x_val.shape[0], numpy.prod(x_val[0,:,:].shape))\n",
    "x_test = x_test.reshape(x_test.shape[0], numpy.prod(x_test[0,:,:].shape))\n",
    "\n",
    "print(x_train.shape)\n",
    "y_train = y_train.astype(numpy.int32)\n",
    "y_val  = y_val.astype(numpy.int32)\n",
    "y_test  = y_test.astype(numpy.int32)\n",
    "\n",
    "print()\n",
    "print('MNIST data loaded: train:',len(x_train),'val:',len(x_val), 'test:',len(x_test))\n",
    "print('X_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "\n",
    "# one-hot encoding:\n",
    "nb_classes = 10\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_val_onehot = tf.keras.utils.to_categorical(y_val, nb_classes)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302994b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import an implementation of a two-layer neural network \n",
    "# this code is based on pieces of the first assignment from Stanford's CSE231n course, \n",
    "# hosted at https://github.com/cs231n/cs231n.github.io with the MIT license\n",
    "from fc_net import TwoLayerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43e3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple implementation of stochastic gradient descent\n",
    "def sgd(model, gradients, learning_rate):\n",
    "    for p, w in model.params.items():\n",
    "        dw = gradients[p]\n",
    "        new_weights = w - learning_rate * dw\n",
    "        model.params[p] = new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8316228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one training step\n",
    "def learn(model, x_train, y_train_onehot, learning_rate):\n",
    "    loss, gradients = model.loss(x_train, y_train_onehot)\n",
    "    sgd(model, gradients, learning_rate)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3faadcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, true_values):\n",
    "    scores = model.loss(x)\n",
    "    predictions = numpy.argmax(scores, axis=1)\n",
    "    N = predictions.shape[0]\n",
    "    # EDIT: squeezing true_values from 2d to 1d speeds up this function\n",
    "    true_values_1d = numpy.squeeze(true_values)\n",
    "    acc = (true_values_1d == predictions).sum() / N\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170952f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT: decided to track how long each epoch takes\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49754891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example training loop using this two-layer model. Can you do better? \n",
    "\n",
    "# EDIT: also track validation data\n",
    "# EDIT: factoring this out into a function to make it easier to compare options\n",
    "def training(learning_rate, batch_size, num_epochs, hidden_dim, weight_scale, x_train, y_train, y_train_onehot, x_val, y_val, y_val_onehot):\n",
    "    num_features = x_train.shape[1] # this is the number of pixels\n",
    "    nb_classes = y_train_onehot.shape[1]\n",
    "    \n",
    "    # The weights are initialized from a normal distribution with standard deviation weight_scale\n",
    "    model = TwoLayerNet(input_dim=num_features, hidden_dim=hidden_dim, num_classes=nb_classes, weight_scale=weight_scale)\n",
    "    \n",
    "    num_examples_train = x_train.shape[0]\n",
    "    num_batches_train = int(num_examples_train / batch_size)\n",
    "    \n",
    "    losses = numpy.zeros((num_batches_train*num_epochs,2)) # 1st column for training data, 2nd for validation data\n",
    "    # EDIT: also track accuracy\n",
    "    accuracies = numpy.zeros((num_batches_train*num_epochs,2)) \n",
    "    \n",
    "    indices_train = numpy.arange(num_examples_train)\n",
    "    num_examples_val = x_val.shape[0]\n",
    "    indices_val = numpy.arange(num_examples_val)\n",
    "\n",
    "    i = 0\n",
    "    for epoch in range(0, num_epochs):\n",
    "        start_epoch = time.time()\n",
    "        # in each epoch, we loop over all of the training examples\n",
    "        for step in range(0, num_batches_train):\n",
    "            # grabbing the next training batch\n",
    "            offset_train = step * batch_size\n",
    "            batch_range_train = range(offset_train, offset_train+batch_size)\n",
    "            x_train_batch = x_train[batch_range_train, :]\n",
    "            # EDIT: keep around non-onehot labels as well for accuracy calculation\n",
    "            y_train_onehot_batch = y_train_onehot[batch_range_train,:]\n",
    "            y_train_batch = y_train[batch_range_train,numpy.newaxis]\n",
    "\n",
    "            # one approach: grab a random validation batch (random offset into number of validation examples)\n",
    "            offset_val = numpy.random.randint(low=0, high=num_examples_val-batch_size)\n",
    "            batch_range_val = range(offset_val, offset_val+batch_size)\n",
    "            x_val_batch = x_val[batch_range_val, :]\n",
    "            y_val_onehot_batch = y_val_onehot[batch_range_val,:]\n",
    "            y_val_batch = y_val[batch_range_val,numpy.newaxis]\n",
    "\n",
    "            # feed the next batch in to do one sgd step\n",
    "            loss_train = learn(model, x_train_batch, y_train_onehot_batch, learning_rate)\n",
    "\n",
    "            # check training & validation loss & accuracy\n",
    "            losses[i,0] = loss_train\n",
    "            \n",
    "            # could save time by commenting out the next three lines and only tracking at the epoch level\n",
    "            accuracies[i,0] = accuracy(model, x_train_batch, y_train_batch)\n",
    "            losses[i,1], _ = model.loss(x_val_batch, y_val_onehot_batch)\n",
    "            accuracies[i,1] = accuracy(model, x_val_batch, y_val_batch)\n",
    "            i += 1\n",
    "\n",
    "        # slower, so we're only doing this once per epoch: checking accuracy on all of the data at once\n",
    "        acc_train = accuracy(model, x_train, y_train)\n",
    "        acc_val = accuracy(model, x_val, y_val)\n",
    "        \n",
    "        # reshuffle the data so that we get a new set of batches\n",
    "        numpy.random.shuffle(indices_train)\n",
    "        x_train = x_train[indices_train,:]\n",
    "        y_train = y_train[indices_train] # keep this shuffled the same way for use in accuracy calculation\n",
    "        y_train_onehot = y_train_onehot[indices_train,:]\n",
    "\n",
    "        numpy.random.shuffle(indices_val)\n",
    "        x_val = x_val[indices_val,:]\n",
    "        y_val = y_val[indices_val] \n",
    "        y_val_onehot = y_val_onehot[indices_val,:]\n",
    "        end_epoch = time.time()\n",
    "        time_this_epoch = end_epoch - start_epoch\n",
    "        print(\"epoch %d took %.1f seconds, training loss %.5f (last batch), training accuracy %.3f, validation accuracy %.3f\" % (epoch, time_this_epoch, loss_train, acc_train, acc_val))\n",
    "    return losses, accuracies, model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a91cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 took 2.7 seconds, training loss 2.30223 (last batch), training accuracy 0.114, validation accuracy 0.110\n",
      "epoch 1 took 3.1 seconds, training loss 2.30105 (last batch), training accuracy 0.121, validation accuracy 0.117\n",
      "epoch 2 took 3.1 seconds, training loss 2.29996 (last batch), training accuracy 0.129, validation accuracy 0.126\n",
      "epoch 3 took 3.0 seconds, training loss 2.29884 (last batch), training accuracy 0.139, validation accuracy 0.136\n",
      "epoch 4 took 3.0 seconds, training loss 2.29788 (last batch), training accuracy 0.149, validation accuracy 0.145\n",
      "epoch 5 took 2.9 seconds, training loss 2.29664 (last batch), training accuracy 0.160, validation accuracy 0.155\n",
      "epoch 6 took 2.9 seconds, training loss 2.29572 (last batch), training accuracy 0.172, validation accuracy 0.167\n",
      "epoch 7 took 2.9 seconds, training loss 2.29457 (last batch), training accuracy 0.186, validation accuracy 0.181\n",
      "epoch 8 took 2.9 seconds, training loss 2.29360 (last batch), training accuracy 0.201, validation accuracy 0.197\n",
      "epoch 9 took 3.0 seconds, training loss 2.29248 (last batch), training accuracy 0.219, validation accuracy 0.216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22708616080>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these are the hyperparameters we had in class\n",
    "learning_rate = 0.01  \n",
    "batch_size = 10000\n",
    "num_epochs = 10\n",
    "hidden_dim = 300\n",
    "weight_scale = .01\n",
    "losses, accuracies, model = training(learning_rate, batch_size, num_epochs, hidden_dim, weight_scale, x_train, y_train, y_train_onehot, x_val, y_val, y_val_onehot)\n",
    "\n",
    "# EDIT: plot training & val, loss & accuracy\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(losses[:,0])\n",
    "plt.plot(losses[:,1])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(accuracies[:,0])\n",
    "plt.plot(accuracies[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd5728",
   "metadata": {},
   "source": [
    "# Homework: improve the accuracy of this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf0515",
   "metadata": {},
   "source": [
    "Update this notebook so that the accuracy is improved. How high can you get it? You could change things directly in the notebook, such as increasing the number of epochs, changing the learning weight, changing the width of the hidden layer, etc. If you're more ambitious, you could also try changing the model definition itself by checking out the associated Python files. For example, you could add more layers to the network. The current notebook has a training accuracy of about 43%, but will vary with randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc9053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10648164021161025\n",
      "epoch 0 took 1.6 seconds, training loss 0.94126 (last batch), training accuracy 0.734, validation accuracy 0.737\n",
      "epoch 1 took 1.6 seconds, training loss 0.57416 (last batch), training accuracy 0.825, validation accuracy 0.826\n",
      "epoch 2 took 1.6 seconds, training loss 0.46473 (last batch), training accuracy 0.857, validation accuracy 0.858\n",
      "epoch 3 took 1.6 seconds, training loss 0.57272 (last batch), training accuracy 0.872, validation accuracy 0.874\n",
      "epoch 4 took 1.6 seconds, training loss 0.33051 (last batch), training accuracy 0.881, validation accuracy 0.881\n",
      "epoch 5 took 1.7 seconds, training loss 0.41479 (last batch), training accuracy 0.888, validation accuracy 0.889\n",
      "epoch 6 took 1.7 seconds, training loss 0.40216 (last batch), training accuracy 0.892, validation accuracy 0.894\n",
      "epoch 7 took 1.6 seconds, training loss 0.30040 (last batch), training accuracy 0.896, validation accuracy 0.898\n",
      "epoch 8 took 1.6 seconds, training loss 0.42115 (last batch), training accuracy 0.900, validation accuracy 0.901\n",
      "epoch 9 took 1.5 seconds, training loss 0.38095 (last batch), training accuracy 0.903, validation accuracy 0.906\n",
      "epoch 10 took 1.6 seconds, training loss 0.43687 (last batch), training accuracy 0.906, validation accuracy 0.907\n",
      "epoch 11 took 1.6 seconds, training loss 0.18358 (last batch), training accuracy 0.908, validation accuracy 0.911\n",
      "epoch 12 took 1.6 seconds, training loss 0.20956 (last batch), training accuracy 0.911, validation accuracy 0.912\n",
      "epoch 13 took 1.5 seconds, training loss 0.37057 (last batch), training accuracy 0.912, validation accuracy 0.913\n",
      "epoch 14 took 1.6 seconds, training loss 0.19196 (last batch), training accuracy 0.914, validation accuracy 0.916\n",
      "epoch 15 took 1.6 seconds, training loss 0.28632 (last batch), training accuracy 0.916, validation accuracy 0.917\n",
      "epoch 16 took 1.6 seconds, training loss 0.19914 (last batch), training accuracy 0.918, validation accuracy 0.918\n",
      "epoch 17 took 1.6 seconds, training loss 0.22997 (last batch), training accuracy 0.920, validation accuracy 0.920\n",
      "epoch 18 took 1.6 seconds, training loss 0.39961 (last batch), training accuracy 0.920, validation accuracy 0.922\n",
      "epoch 19 took 1.6 seconds, training loss 0.21505 (last batch), training accuracy 0.922, validation accuracy 0.923\n",
      "epoch 20 took 1.6 seconds, training loss 0.35596 (last batch), training accuracy 0.924, validation accuracy 0.924\n",
      "epoch 21 took 1.6 seconds, training loss 0.32274 (last batch), training accuracy 0.926, validation accuracy 0.924\n",
      "epoch 22 took 1.7 seconds, training loss 0.29466 (last batch), training accuracy 0.927, validation accuracy 0.926\n",
      "epoch 23 took 1.6 seconds, training loss 0.23147 (last batch), training accuracy 0.927, validation accuracy 0.926\n",
      "epoch 24 took 1.6 seconds, training loss 0.24086 (last batch), training accuracy 0.929, validation accuracy 0.928\n",
      "epoch 25 took 1.6 seconds, training loss 0.26810 (last batch), training accuracy 0.930, validation accuracy 0.929\n",
      "epoch 26 took 1.7 seconds, training loss 0.29444 (last batch), training accuracy 0.931, validation accuracy 0.929\n",
      "epoch 27 took 1.6 seconds, training loss 0.31644 (last batch), training accuracy 0.931, validation accuracy 0.930\n",
      "epoch 28 took 1.6 seconds, training loss 0.15019 (last batch), training accuracy 0.933, validation accuracy 0.932\n",
      "epoch 29 took 1.6 seconds, training loss 0.26101 (last batch), training accuracy 0.933, validation accuracy 0.933\n",
      "epoch 30 took 1.6 seconds, training loss 0.23287 (last batch), training accuracy 0.934, validation accuracy 0.933\n",
      "epoch 31 took 1.6 seconds, training loss 0.23769 (last batch), training accuracy 0.935, validation accuracy 0.934\n",
      "epoch 32 took 1.6 seconds, training loss 0.18743 (last batch), training accuracy 0.937, validation accuracy 0.935\n",
      "epoch 33 took 1.6 seconds, training loss 0.25936 (last batch), training accuracy 0.937, validation accuracy 0.935\n",
      "epoch 34 took 1.6 seconds, training loss 0.33462 (last batch), training accuracy 0.938, validation accuracy 0.936\n",
      "epoch 35 took 1.6 seconds, training loss 0.19812 (last batch), training accuracy 0.938, validation accuracy 0.937\n",
      "epoch 36 took 1.7 seconds, training loss 0.14785 (last batch), training accuracy 0.939, validation accuracy 0.938\n",
      "epoch 37 took 1.6 seconds, training loss 0.25190 (last batch), training accuracy 0.940, validation accuracy 0.938\n",
      "epoch 38 took 1.6 seconds, training loss 0.20143 (last batch), training accuracy 0.941, validation accuracy 0.939\n",
      "epoch 39 took 1.6 seconds, training loss 0.08394 (last batch), training accuracy 0.941, validation accuracy 0.940\n",
      "epoch 40 took 1.7 seconds, training loss 0.42741 (last batch), training accuracy 0.943, validation accuracy 0.940\n"
     ]
    }
   ],
   "source": [
    "# Here's an example network that is much more accurate. I experimented with each hyperparameter one at a time\n",
    "# The training took about 11 seconds per epoch on my laptop, and the final validation accuracy was 94%\n",
    "# It's much slower on ThetaGPU's single-gpu queue, since it doesn't take advantage of a GPU and is stuck using\n",
    "# a portion of one of the node's CPUs. \n",
    "# (With some effort, you can convert everything to CuPy instead of NumPy and then it runs on the GPU)\n",
    "# If you don't have your own computer to run on, you might want to use Google Colab. \n",
    "learning_rate = 0.01  \n",
    "batch_size = 100\n",
    "num_epochs = 100\n",
    "hidden_dim = 64\n",
    "# Try Xavier initialization, although need to use same scaling for both layers, so averaging\n",
    "# https://keras.io/api/layers/initializers/\n",
    "size_input = x_train.shape[1]\n",
    "weight_scale1 = numpy.sqrt(2./(size_input+hidden_dim))\n",
    "weight_scale2 = numpy.sqrt(2./(hidden_dim+nb_classes))\n",
    "weight_scale = (weight_scale1 + weight_scale2)/2\n",
    "print(weight_scale)\n",
    "losses, accuracies, model = training(learning_rate, batch_size, num_epochs, hidden_dim, weight_scale, x_train, y_train, y_train_onehot, x_val, y_val, y_val_onehot)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(losses[:,0])\n",
    "plt.plot(losses[:,1])\n",
    "plt.legend([\"train\", \"val\"])\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(accuracies[:,0])\n",
    "plt.plot(accuracies[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacaeba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
